## HTTP/1.x 的连接管理
HTTP 的传输协议主要依赖于 TCP 来提供从客户端到服务器端之间的连接。在早期，HTTP 使用一个简单的模型来处理这样的连接。这些连接的生命周期是短暂的：每发起一个请求时都会创建一个新的连接，并在收到应答时立即关闭。

这个简单的模型对性能有先天的限制：打开每一个 TCP 连接都是相当耗费资源的操作。

有两个新的模型在 HTTP/1.1 诞生了。首先是长连接模型，它会保持连接去完成多次连续的请求，减少了不断重新打开连接的时间。然后是 HTTP 流水线模型，它还要更先进一些，多个连续的请求甚至都不用等待立即返回就可以被发送，这样就减少了耗费在网络延迟上的时间。

<img src="./assets/HTTP1_x_Connections.png">

默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。那就可能会导致 Head of Line blocking (HOL) ，在下文会讲解在HTTP2.0中是如何解决的
## Http/2.0
HTTP/2 协议的主要目的是提高网页性能。
### 1. 头部压缩
头信息（header）原来是直接传输文本，现在是压缩后传输

### 2. 多路复用
代替原来的序列和阻塞机制，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制
<img src="./assets/mult.jpeg">

在Http/2 中，同域名下所有通信都在单个连接上完成。如此一来，更可能会带来 HOL, 那如何解决呢？ /*（以下描述仅代表个人观点）*/
- 请求id，每个请求都带上独一无二的标识
- 序列号，HTTP/2 中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。（类似于 Tcp 中的序列号）

可以说在一定程度上，这个是通过浪费性能，解决 HOL 问题


总结：
- 同个域名只需要占用一个 TCP 连接，消除了因多个 TCP 连接而带来的延时和内存消耗。
- 单个连接可以承载任意数量的双向数据流
- 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。

### 3. Server push
访问一个网页，一般是需求分别发送请求，去请求HTML、CSS、JS，那么可能会有什么问题呢？
- 至少需要三轮 HTTP 通信
- 如果样式文件响应慢，会网页无样式，这个阶段一旦超过2秒，用户体验就会非常不好

可以理解为是RTT（Round Trip Time，也就是一个数据包从发出去到回来的时间） 问题，那么有没有好的方式去解决呢？

Server Push来喽~

<img src="./assets/serverPush.png">

不过，需要开发者自己配置。不过在实际开发中也遇到了一些其他问题~

**浏览器缓存 VS Server Push**

比如有，网站资源大小分别问，html文件 1k，css文件 1k, js 1.2M。此时，js、css 资源已经在浏览器缓存，当我们请求 html 资源时，推送回了我们不需要的js、css资源，从而在成宽带的浪费，所以需要了解浏览器缓存了哪些资源

### 总结
需要注意的是，在网络环境比较差的环境下，Http/2 有可能会比 Http/1 体验要差，因为Http/1 中，可以开多个Tcp连接
## Http3
我们知道 Http/2 是基于Tcp协议的，对于拥塞控制是由操作系统决定的。Http/3 是基于UDP协议的，这样拥塞控制可以由浏览器来控制

## TCP
关于TCP，除了三次握手、四次挥手，我们应该了解
- 拥塞控制：为防止网络瘫痪，在通信一开始就会通过一个叫慢启动的算法得出的数值，对数据量进行控制。过程中，会根据确认应答数，不断调整拥塞窗口的大小。有点像是“君子协议”
- 流量控制：这种机制让发送端根据接收端的实际接收能力控制发送数量。如果说拥塞控制是“君子协议”，那么不得不说，流量控制，就是法律，不得不遵从

补充下，猜想为什么“迅雷”下载资源会快呢？猜想
- 服务器，多 TCP
- 多 TCP 增加了滑动窗口


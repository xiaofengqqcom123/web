https://www.yuque.com/antv/g6-blog/krn6bg


在大数据下的关系网络可视化中，笔者推荐优先使用交互优化，在交互无法进行优化时再使用性能优化方案。原因是，在交互上优化不仅仅是解决性能问题，是真正的从用户的角度出发解决用户做分析理解数据的工作时的体验问题。而提升性能肯定是在当前交互已经是目前能想到的方案中最好的方案的前提下才做，当交互本身无法让用户有好的体验时，性能再好那都是没有意义的。
另外，上面所述的方法均是笔者在学习过程中总结、思考所得，特别是交互部分并未在真实项目中实践过。故有纸上谈兵之嫌，若有分析理解不到位之处还烦请不吝赐教。

# 性能提升

绘图过程中出现的性能问题通常都在计算上，也就是在渲染过程中出现卡顿现象的性能问题。接下来我们讨论的几个解决方案都是解决这类性能问题的。

## webGL
首当其冲的是启用webGL，这个效果是立竿见影的，我们先看效果后说话。

测试例子：随机构建N个节点数据，然后使用此数据在画布上绘制方块，检测构建节点、绘制时间和。测试数据如下：
| 构建节点数 | canvas(ms) | webGL(ms) |
| ---- | ---- | ---- |
| 2000 | 约10 | 约50 |
| 20000 | 约300 | 约80 |
| 200000 | 约3000 | 约200 |
| 800000 | 约12000 | 约500 |

根据以上测试的测试数据，我们得到以下三个性能的结论：
1. 使用普通canvas绘制随着节点数的不断增加耗时也随之递增，而且增幅接近1:1。
2. 使用webgl，随着节点数的增加，其耗时增幅要缓的多。
3. 节点数越多，canvas和webGL的耗时差距越大。

既然webGL这么好，那么就直接上webGL吧？webGL随好，但它也有个致命的弱点，那就是代码复杂，开发成本高。至于webGL复杂在哪里，为什么复杂，有兴趣的同学可以搜索相关资料进行了解；笔者贴上示例代码，希望给读者有个直观的感受，但不做过多讨论。 

```
// GLSL ES语言
// 顶点着色器
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' +
    'void main() {\n' +
    '  gl_Position = a_Position;\n' +
    '  gl_PointSize = 10.0;\n' +
    '}\n';

// 片元着色器
var FSHADER_SOURCE =
    'void main() {\n' +
    '  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n' +
    '}\n';

// webGL上下文
const gl = getWebGLContext(canvas);
initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE);

// mockData为生成模拟数据的方法
const { nodes } = mockData(800000, true);
const verts = [];
nodes.forEach((node) => {
    verts.push(node.x);
    verts.push(node.y);
});
const vertices = new Float32Array(verts);
// 创建缓存区
const vertexBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
const a_Position = gl.getAttribLocation(gl.program, 'a_Position');
gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(a_Position);

gl.clearColor(0.0, 0.0, 0.0, 1.0);

gl.clear(gl.COLOR_BUFFER_BIT);

gl.drawArrays(gl.POINTS, 0, nodes.length);
```

webGL之所以有如此大的威力那是因为它使用了GPU加速，至于为什么使用GPU之后速度就快推荐大家看《CPU和GPU的设计区别》一文。简单总结就是：CPU要处理的事情繁杂且多（有点像全才），什么事情都亲力亲为自然是要忙不过来的；GPU只干它擅长的事情（有点像专才），自然干得又快又好。

## web workers
关于web workers想必大家肯定或多或少的听说过，它可以单独开辟出一个线程而对主线程无干扰。换言之，就是我们可以将部分计算移到web workers里去进行异步执行，结果返回后再融入到主线中；如此在web workers里执行时，不会阻塞主线里的任务执行。

但是web workers有一个重要的限制是不能访问DOM和其他资源，基于这个限制它有很多事情是做不了的。

我们可以使用web workers做复杂数学计算、复杂数据排序、数据处理（压缩、图像处理...）、高流量网络通信这些事情。比如在上面webGL代码中，我们可以将21 - 26行代码的内容提取出来放到worker里进行处理；它可以为主线程剩下近400ms时间(以构建800000节点为例)。

但上面的计算方式是一种理想状态，事实上开启web workers本身也是消耗资源的，实际耗时会比上述更长一些。另外，上面示例太过简单，当worker在运行时主线程反而闲着有些得不偿失。只有当将计算丢给worker运行，而主线程又不会闲着的时候才能真正体现出worker的价值来。下面的代码简单示意worker的使用方式，更多用法请自行查阅文档。

### 代码示例
```javascript
// 主线程代码
const worker = new Worker('./worker.js'); // worker.js为在worker线程中执行的代码文件
worker.postMessage({data}); // 向worker发送信息
worker.onmessage = function (evt) {
    // 接收信息后的回调
}

// worker.js worker线程代码
onmessage = ()=>({
    postMessage(); // worker向主线程发送消息
})
``` 

## requestAnimationFrame
使用requestAnimationFrame是为了将代码切割成多个片段执行，以至于不阻塞其他更重要的代码执行(如用户的操作)。下面以渲染1亿个节点为例：

```
const width = 1000;
const height = 1000;
const offsetX = width/2;
const offsetY = height/2;

const container = document.getElementById('container');
const canvas = document.createElement('canvas');
canvas.width = width;
canvas.height = height;
canvas.style.border = '1px solid #ddd';
container.appendChild(canvas);
const ctx = canvas.getContext('2d');

const pre = 5000; // 每次渲染的节点数
const count = Math.floor(100000000/pre);
let times = 0;

start();

function start() {
    if (times < count) { // 使用requestAnimationFrame分隔多次执行
        requestAnimationFrame(start);
    }
    for (let i=0; i<pre; i++) {
        const x = Math.random() * width;
        const y = Math.random() * height;
        ctx.beginPath();
        ctx.arc(x, y, 15, 0, 2 * Math.PI);
        ctx.fillStyle = 'rgba(255, 100, 0, .01)';
        ctx.fill();
    }
    times ++;
}
```

在显然过程中，用户能够清晰的感觉到数据是被分批渲染上来的，但是不会有任何卡顿的感觉，总体来说体验还是不错的。如果不采用此法，用户就可能需要在那里不知所措的等上几十秒才能看到渲染结果。
requestAnimationFrame就像一个安慰剂，它只是让用户不明显的感受到页面的卡顿——那种让人窒息的感觉；但实际并不减少总耗时，事实上是有增无减。

